{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initial setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T06:41:51.897648Z",
     "start_time": "2021-06-06T06:41:51.602378Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "from data import cfg_mnet, cfg_re50\n",
    "from layers.functions.prior_box import PriorBox\n",
    "from utils.nms.py_cpu_nms import py_cpu_nms\n",
    "import cv2\n",
    "from models.retinaface import RetinaFace\n",
    "from utils.box_utils import decode, decode_landm\n",
    "import time\n",
    "import easydict\n",
    "\n",
    "args = easydict.EasyDict({ \n",
    "    \"trained_model\": './weights/mobilenet0.25_Final.pth', \n",
    "    'network': 'mobile0.25',\n",
    "    \"cpu\": False, \n",
    "    \"confidence_threshold\": 0.02, \n",
    "    \"top_k\": 5000, \n",
    "    \"nms_threshold\": 0.4,\n",
    "    'keep_top_k':750,\n",
    "    'save_image':True,\n",
    "    'vis_thres':0.9\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T06:41:52.494456Z",
     "start_time": "2021-06-06T06:41:52.487862Z"
    }
   },
   "outputs": [],
   "source": [
    "def check_keys(model, pretrained_state_dict):\n",
    "    ckpt_keys = set(pretrained_state_dict.keys())\n",
    "    model_keys = set(model.state_dict().keys())\n",
    "    used_pretrained_keys = model_keys & ckpt_keys\n",
    "    unused_pretrained_keys = ckpt_keys - model_keys\n",
    "    missing_keys = model_keys - ckpt_keys\n",
    "    print('Missing keys:{}'.format(len(missing_keys)))\n",
    "    print('Unused checkpoint keys:{}'.format(len(unused_pretrained_keys)))\n",
    "    print('Used keys:{}'.format(len(used_pretrained_keys)))\n",
    "    assert len(used_pretrained_keys) > 0, 'load NONE from pretrained checkpoint'\n",
    "    return True\n",
    "\n",
    "\n",
    "def remove_prefix(state_dict, prefix):\n",
    "    ''' Old style model is stored with all names of parameters sharing common prefix 'module.' '''\n",
    "    print('remove prefix \\'{}\\''.format(prefix))\n",
    "    f = lambda x: x.split(prefix, 1)[-1] if x.startswith(prefix) else x\n",
    "    return {f(key): value for key, value in state_dict.items()}\n",
    "\n",
    "\n",
    "def load_model(model, pretrained_path, load_to_cpu):\n",
    "    print('Loading pretrained model from {}'.format(pretrained_path))\n",
    "    if load_to_cpu:\n",
    "        pretrained_dict = torch.load(pretrained_path, map_location=lambda storage, loc: storage)\n",
    "    else:\n",
    "        device = torch.cuda.current_device()\n",
    "        pretrained_dict = torch.load(pretrained_path, map_location=lambda storage, loc: storage.cuda(device))\n",
    "    if \"state_dict\" in pretrained_dict.keys():\n",
    "        pretrained_dict = remove_prefix(pretrained_dict['state_dict'], 'module.')\n",
    "    else:\n",
    "        pretrained_dict = remove_prefix(pretrained_dict, 'module.')\n",
    "    check_keys(model, pretrained_dict)\n",
    "    model.load_state_dict(pretrained_dict, strict=False)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T06:41:54.920820Z",
     "start_time": "2021-06-06T06:41:53.475637Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained model from ./weights/mobilenet0.25_Final.pth\n",
      "remove prefix 'module.'\n",
      "Missing keys:0\n",
      "Unused checkpoint keys:0\n",
      "Used keys:300\n",
      "Finished loading model!\n",
      "RetinaFace(\n",
      "  (body): IntermediateLayerGetter(\n",
      "    (stage1): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Conv2d(3, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n",
      "        (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)\n",
      "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (3): Sequential(\n",
      "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (4): Sequential(\n",
      "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (5): Sequential(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (stage2): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (3): Sequential(\n",
      "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (4): Sequential(\n",
      "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (5): Sequential(\n",
      "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (stage3): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (fpn): FPN(\n",
      "    (output1): Sequential(\n",
      "      (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (output2): Sequential(\n",
      "      (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (output3): Sequential(\n",
      "      (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (merge1): Sequential(\n",
      "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (merge2): Sequential(\n",
      "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (ssh1): SSH(\n",
      "    (conv3X3): Sequential(\n",
      "      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (conv5X5_1): Sequential(\n",
      "      (0): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (conv5X5_2): Sequential(\n",
      "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (conv7X7_2): Sequential(\n",
      "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (conv7x7_3): Sequential(\n",
      "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (ssh2): SSH(\n",
      "    (conv3X3): Sequential(\n",
      "      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (conv5X5_1): Sequential(\n",
      "      (0): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (conv5X5_2): Sequential(\n",
      "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (conv7X7_2): Sequential(\n",
      "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (conv7x7_3): Sequential(\n",
      "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (ssh3): SSH(\n",
      "    (conv3X3): Sequential(\n",
      "      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (conv5X5_1): Sequential(\n",
      "      (0): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (conv5X5_2): Sequential(\n",
      "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (conv7X7_2): Sequential(\n",
      "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (conv7x7_3): Sequential(\n",
      "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (ClassHead): ModuleList(\n",
      "    (0): ClassHead(\n",
      "      (conv1x1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): ClassHead(\n",
      "      (conv1x1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): ClassHead(\n",
      "      (conv1x1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (BboxHead): ModuleList(\n",
      "    (0): BboxHead(\n",
      "      (conv1x1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): BboxHead(\n",
      "      (conv1x1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): BboxHead(\n",
      "      (conv1x1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (LandmarkHead): ModuleList(\n",
      "    (0): LandmarkHead(\n",
      "      (conv1x1): Conv2d(64, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (1): LandmarkHead(\n",
      "      (conv1x1): Conv2d(64, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (2): LandmarkHead(\n",
      "      (conv1x1): Conv2d(64, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "torch.set_grad_enabled(False)\n",
    "cfg = None\n",
    "if args.network == \"mobile0.25\":\n",
    "    cfg = cfg_mnet\n",
    "elif args.network == \"resnet50\":\n",
    "    cfg = cfg_re50\n",
    "# net and model\n",
    "net = RetinaFace(cfg=cfg, phase = 'test')\n",
    "net = load_model(net, args.trained_model, args.cpu)\n",
    "net.eval()\n",
    "print('Finished loading model!')\n",
    "print(net)\n",
    "cudnn.benchmark = True\n",
    "device = torch.device(\"cpu\" if args.cpu else \"cuda\")\n",
    "net = net.to(device)\n",
    "\n",
    "resize = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T06:42:08.287548Z",
     "start_time": "2021-06-06T06:41:57.847987Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "net forward time: 0.2719\n"
     ]
    }
   ],
   "source": [
    "image_path = \"./curve/test.jpg\"\n",
    "img_raw = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "\n",
    "img = np.float32(img_raw)\n",
    "\n",
    "im_height, im_width, _ = img.shape\n",
    "scale = torch.Tensor([img.shape[1], img.shape[0], img.shape[1], img.shape[0]])\n",
    "img -= (104, 117, 123)\n",
    "img = img.transpose(2, 0, 1)\n",
    "img = torch.from_numpy(img).unsqueeze(0)\n",
    "img = img.to(device)\n",
    "scale = scale.to(device)\n",
    "\n",
    "tic = time.time()\n",
    "loc, conf, landms = net(img)  # forward pass\n",
    "print('net forward time: {:.4f}'.format(time.time() - tic))\n",
    "\n",
    "priorbox = PriorBox(cfg, image_size=(im_height, im_width))\n",
    "priors = priorbox.forward()\n",
    "priors = priors.to(device)\n",
    "prior_data = priors.data\n",
    "boxes = decode(loc.data.squeeze(0), prior_data, cfg['variance'])\n",
    "boxes = boxes * scale / resize\n",
    "boxes = boxes.cpu().numpy()\n",
    "scores = conf.squeeze(0).data.cpu().numpy()[:, 1]\n",
    "landms = decode_landm(landms.data.squeeze(0), prior_data, cfg['variance'])\n",
    "scale1 = torch.Tensor([img.shape[3], img.shape[2], img.shape[3], img.shape[2],\n",
    "                       img.shape[3], img.shape[2], img.shape[3], img.shape[2],\n",
    "                       img.shape[3], img.shape[2]])\n",
    "scale1 = scale1.to(device)\n",
    "landms = landms * scale1 / resize\n",
    "landms = landms.cpu().numpy()\n",
    "\n",
    "# ignore low scores\n",
    "inds = np.where(scores > args.confidence_threshold)[0]\n",
    "boxes = boxes[inds]\n",
    "landms = landms[inds]\n",
    "scores = scores[inds]\n",
    "\n",
    "# keep top-K before NMS\n",
    "order = scores.argsort()[::-1][:args.top_k]\n",
    "boxes = boxes[order]\n",
    "landms = landms[order]\n",
    "scores = scores[order]\n",
    "\n",
    "# do NMS\n",
    "dets = np.hstack((boxes, scores[:, np.newaxis])).astype(np.float32, copy=False)\n",
    "keep = py_cpu_nms(dets, args.nms_threshold)\n",
    "# keep = nms(dets, args.nms_threshold,force_cpu=args.cpu)\n",
    "dets = dets[keep, :]\n",
    "landms = landms[keep]\n",
    "\n",
    "# keep top-K faster NMS\n",
    "dets = dets[:args.keep_top_k, :]\n",
    "landms = landms[:args.keep_top_k, :]\n",
    "\n",
    "dets = np.concatenate((dets, landms), axis=1)\n",
    "\n",
    "# show image (확인)\n",
    "for b in dets:\n",
    "    if b[4] < args.vis_thres:\n",
    "        continue\n",
    "    text = \"{:.4f}\".format(b[4])\n",
    "    b = list(map(int, b))\n",
    "    cv2.rectangle(img_raw, (b[0], b[1]), (b[2], b[3]), (0, 0, 255), 2)\n",
    "\n",
    "cv2.imshow('img', img_raw)\n",
    "#ESC키를 누르면 break로 종료\n",
    "k = cv2.waitKey(10000)\n",
    "#if k == 27 : break        \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T06:42:11.297898Z",
     "start_time": "2021-06-06T06:42:11.201028Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T06:42:13.189174Z",
     "start_time": "2021-06-06T06:42:12.531051Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/unist/.cache/torch/hub/pytorch_vision_v0.8.2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       "  )\n",
       "  (1): Linear(in_features=1000, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_path = './model_1.pth'\n",
    "resnet = torch.hub.load('pytorch/vision:v0.8.2', 'resnet18', pretrained=True)\n",
    "model = nn.Sequential(resnet, nn.Linear(in_features=1000, out_features=7, bias=True))\n",
    "baseline_model = torch.load(baseline_path)\n",
    "model.load_state_dict(baseline_model)\n",
    "model.eval()\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.5752, 0.4495, 0.4012],\n",
    "                                 std=[0.2086, 0.1911, 0.1827])\n",
    "\n",
    "test_transform = transforms.Compose([transforms.Resize((224,224)),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     normalize])\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T06:42:27.287404Z",
     "start_time": "2021-06-06T06:42:14.746925Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "net forward time: 0.0057\n"
     ]
    }
   ],
   "source": [
    "image_path = \"./curve/test.jpg\"\n",
    "img_raw = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "\n",
    "img = np.float32(img_raw)\n",
    "im_height, im_width, _ = img.shape\n",
    "scale = torch.Tensor([img.shape[1], img.shape[0], img.shape[1], img.shape[0]])\n",
    "img -= (104, 117, 123)\n",
    "img = img.transpose(2, 0, 1)\n",
    "img = torch.from_numpy(img).unsqueeze(0)\n",
    "img = img.to(device)\n",
    "scale = scale.to(device)\n",
    "\n",
    "tic = time.time()\n",
    "loc, conf, landms = net(img)  # forward pass\n",
    "print('net forward time: {:.4f}'.format(time.time() - tic))\n",
    "\n",
    "priorbox = PriorBox(cfg, image_size=(im_height, im_width))\n",
    "priors = priorbox.forward()\n",
    "priors = priors.to(device)\n",
    "prior_data = priors.data\n",
    "boxes = decode(loc.data.squeeze(0), prior_data, cfg['variance'])\n",
    "boxes = boxes * scale / resize\n",
    "boxes = boxes.cpu().numpy()\n",
    "scores = conf.squeeze(0).data.cpu().numpy()[:, 1]\n",
    "landms = decode_landm(landms.data.squeeze(0), prior_data, cfg['variance'])\n",
    "scale1 = torch.Tensor([img.shape[3], img.shape[2], img.shape[3], img.shape[2],\n",
    "                       img.shape[3], img.shape[2], img.shape[3], img.shape[2],\n",
    "                       img.shape[3], img.shape[2]])\n",
    "scale1 = scale1.to(device)\n",
    "landms = landms * scale1 / resize\n",
    "landms = landms.cpu().numpy()\n",
    "\n",
    "# ignore low scores\n",
    "inds = np.where(scores > args.confidence_threshold)[0]\n",
    "boxes = boxes[inds]\n",
    "landms = landms[inds]\n",
    "scores = scores[inds]\n",
    "\n",
    "# keep top-K before NMS\n",
    "order = scores.argsort()[::-1][:args.top_k]\n",
    "boxes = boxes[order]\n",
    "landms = landms[order]\n",
    "scores = scores[order]\n",
    "\n",
    "# do NMS\n",
    "dets = np.hstack((boxes, scores[:, np.newaxis])).astype(np.float32, copy=False)\n",
    "keep = py_cpu_nms(dets, args.nms_threshold)\n",
    "# keep = nms(dets, args.nms_threshold,force_cpu=args.cpu)\n",
    "dets = dets[keep, :]\n",
    "landms = landms[keep]\n",
    "\n",
    "# keep top-K faster NMS\n",
    "dets = dets[:args.keep_top_k, :]\n",
    "landms = landms[:args.keep_top_k, :]\n",
    "\n",
    "dets = np.concatenate((dets, landms), axis=1)\n",
    "\n",
    "face_list = []\n",
    "face_tensor_list = []\n",
    "b_list = []\n",
    "\n",
    "# show image\n",
    "for b in dets:\n",
    "    if b[4] < args.vis_thres:\n",
    "        continue\n",
    "    text = \"{:.4f}\".format(b[4])\n",
    "    b = list(map(int, b))\n",
    "    coord = b[:4]\n",
    "    face = img_raw[coord[1]:coord[3], coord[0]:coord[2]]\n",
    "    face_list.append(face)\n",
    "    face_tensor_list.append(test_transform(transforms.ToPILImage()(face)))\n",
    "    b_list.append(b)\n",
    "    \n",
    "if len(face_tensor_list)!=0:    \n",
    "    inputs = torch.stack(face_tensor_list).to(device)\n",
    "    outputs = model(inputs)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "for i in range(len(face_list)):\n",
    "    b = b_list[i]\n",
    "    cv2.rectangle(img_raw, (b[0], b[1]), (b[2], b[3]), (0, 0, 255), 2)\n",
    "\n",
    "cv2.imshow('img', img_raw)\n",
    "k = cv2.waitKey(10000)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T06:42:29.194093Z",
     "start_time": "2021-06-06T06:42:29.191001Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 5, 1, 1, 5, 5, 5, 4, 0, 5, 2, 6, 3, 0, 0, 0, 1, 0, 0, 0, 2, 1, 0],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T06:42:30.742121Z",
     "start_time": "2021-06-06T06:42:30.740011Z"
    }
   },
   "outputs": [],
   "source": [
    "class_dic = {0: 'Neutral', 1: 'Happiness', 2: 'Sadness', 3: 'Surprise', 4: 'Fear', 5: 'Disgust', 6: 'Anger'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T06:42:31.953062Z",
     "start_time": "2021-06-06T06:42:31.950128Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Happiness'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_dic[int(predicted[0])]"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "271.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
